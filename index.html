<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8"/>
<title>JARVIS AI Voice Assistant</title>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<style>
    html, body {
        height:100%;
        margin:0;
        background:#000000; /* Black background */
        display:flex;
        justify-content:center;
        align-items:center;
        font-family:Arial, Helvetica, sans-serif;
    }
    .voice-button {
        width:150px;
        height:150px;
        cursor:pointer;
        display:flex;
        justify-content:center;
        align-items:center;
        background:#000; /* Black button background */
        border-radius:50%;
        position:relative;
        transition:.2s;
    }
    .voice-button:hover { transform:scale(1.05); }

    /* Ring animation */
    .ring {
        position:absolute;
        width:170px;
        height:170px;
        border:3px solid #0ff;
        border-radius:50%;
        top:-10px;
        left:-10px;
        animation: rotateRing 1s linear infinite;
        display:none;
        box-shadow: 0 0 15px #0ff;
    }

    @keyframes rotateRing {
        0% { transform: rotate(0deg); }
        100% { transform: rotate(360deg); }
    }

    .voice-button img {
        width:130px;
        height:130px;
        border-radius:50%;
        cursor:pointer;
        z-index:2;
    }
</style>
</head>
<body>

<div id="hexBtn" class="voice-button">
    <div class="ring" id="ring"></div>
    <img id="micImage" src="mic.png" alt="Mic Button">
</div>

<audio id="clickSound" src="jarvis-sound.mp3"></audio>

<script>
const micImage   = document.getElementById("micImage");
const clickSound = document.getElementById("clickSound");
const ring       = document.getElementById("ring");

// ELEVENLABS API KEY
const API_KEY   = "sk_44252ff8b6193c316ba00d473053b5410507fe4918f0cb5d";
const VOICE_ID  = "EXAVITQu4vr4xnSDxMaL"; 
const TTS_URL   = `https://api.elevenlabs.io/v1/text-to-speech/${VOICE_ID}/stream`;

// Basic replies
function getResponse(text){
    text = text.trim().toLowerCase();
    if(text.includes("hello")) return "Hello sir.";
    if(text.includes("who are you")) return "I am Jarvis, your personal AI assistant.";
    if(text.includes("time")) return "The current time is " + new Date().toLocaleTimeString();
    if(text.includes("date")) return "Today is " + new Date().toLocaleDateString();
    if(text.includes("2+4")) return "Six";
    return "Sorry sir, I did not understand.";
}

// Play TTS voice
async function speak(text){
    try {
        const response = await fetch(TTS_URL,{
            method:"POST",
            headers:{
                "Content-Type":"application/json",
                "xi-api-key":API_KEY
            },
            body:JSON.stringify({
              text:text,
              voice_settings:{stability:0.40,similarity_boost:0.75}
            })
        });
        const blob = await response.blob();
        const url  = URL.createObjectURL(blob);
        const audio = new Audio(url);
        audio.play();
    } catch(err){
        console.error("TTS error:", err);
    }
}

// Speech recognition
let recognition;
if('webkitSpeechRecognition' in window){
    recognition = new webkitSpeechRecognition();
    recognition.lang = "en-US";
    recognition.onresult = (e)=>{
        const transcript = e.results[0][0].transcript;
        console.log("User said:", transcript);
        const reply = getResponse(transcript);
        speak(reply);
        // Stop ring after response
        ring.style.display = "none";
    }
}

// Click event on image to start recognition
micImage.onclick = ()=>{
    clickSound.currentTime = 0;
    clickSound.play();
    ring.style.display = "block"; // Show ring animation
    if(recognition) recognition.start();
}
</script>

</body>
</html>